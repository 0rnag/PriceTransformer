{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from alpaca.data.historical import CryptoHistoricalDataClient\n",
    "from alpaca.data.requests import CryptoBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame, TimeFrameUnit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = CryptoHistoricalDataClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35108\n",
      "torch.Size([35108, 7])\n"
     ]
    }
   ],
   "source": [
    "request_params = CryptoBarsRequest(\n",
    "    symbol_or_symbols=[\"BTC/USD\"],\n",
    "    timeframe=TimeFrame(amount=15, unit=TimeFrameUnit('Min')),\n",
    "    #timeframe=TimeFrame.Minute,\n",
    "    start=\"2023-05-18\",\n",
    "    end=\"2024-05-18\"\n",
    ")\n",
    "\n",
    "btc_bars = client.get_crypto_bars(request_params=request_params)\n",
    "\n",
    "#print(btc_bars[\"BTC/USD\"])\n",
    "\n",
    "dates = []\n",
    "stats = []\n",
    "for item in btc_bars[\"BTC/USD\"]:\n",
    "    dates.append(dict(item)['timestamp'])\n",
    "    \n",
    "    temp_stats = []\n",
    "    for key, value in dict(item).items():\n",
    "        if key not in ['timestamp', 'symbol']:\n",
    "            temp_stats.append(value) \n",
    "    stats.append(temp_stats)\n",
    "\n",
    "print(len(stats))\n",
    "    \n",
    "data = torch.tensor(stats)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a real number, not 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/btc_minute_23-05-18_24-05-18.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m----> 5\u001b[0m     string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      7\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(string)\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'list'"
     ]
    }
   ],
   "source": [
    "f = open('data/btc_minute_23-05-18_24-05-18.csv', 'a')\n",
    "\n",
    "for item in data:\n",
    "    \n",
    "    string = ', '.join(str(list(item))) + '\\n'\n",
    "\n",
    "    f.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_period = 60\n",
    "feature_space = 7\n",
    "output_size = 3 #[down, no change, up]\n",
    "batch_size = 16\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'mps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BTCDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        random_index = torch.randint(0, len(self.data) - time_period, size=(1,))\n",
    "        return self.data[random_index:random_index+time_period+1]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = BTCDataset(data)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 61, 7])\n"
     ]
    }
   ],
   "source": [
    "for item in dataloader:\n",
    "    print(item.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 4 * embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embedding_dim, embedding_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "    \n",
    "class Head(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout, embedding_dim, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(embedding_dim, head_size, bias=False)\n",
    "        self.query = nn.Linear(embedding_dim, head_size, bias=False)\n",
    "        self.value = nn.Linear(embedding_dim, head_size, bias=False)\n",
    "        #self.register_buffer('tril', torch.tril(torch.ones(time_period, time_period)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T, C = x.shape\n",
    "        k = self.key(x) #(B, T, head_size)\n",
    "        q = self.query(x) #(B, T, head_size)\n",
    "        att = q @ k.transpose(-2, -1) * (k.size(-1) ** -0.5) # Want (B, T, T) where there is a value for how each token relates to each other token\n",
    "        # want k to be (B, C, T) k.transpose(-2, -1) swaps the last 2 dimensions, giving (B, C, T)\n",
    "        #att = att.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        att = F.softmax(att, dim=-1) \n",
    "        att = self.dropout(att)\n",
    "        v = self.value(x)\n",
    "        out = att @ v\n",
    "        return out\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self, dropout, embedding_dim, head_size, num_heads):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(dropout, embedding_dim, head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout, embedding_dim, head_size, num_heads):\n",
    "        super().__init__()\n",
    "        self.self_att = MultiHeadAttention(dropout, embedding_dim, head_size, num_heads)\n",
    "        self.ffwd = FeedForward(dropout, embedding_dim)\n",
    "        self.ln1 = nn.LayerNorm(embedding_dim)\n",
    "        self.ln2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.self_att(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout, embedding_dim, num_heads, head_size, num_layers):\n",
    "        super().__init__()\n",
    "        self.data_embedding = nn.Linear(feature_space, embedding_dim)\n",
    "        self.position_embedding = nn.Embedding(time_period, embedding_dim)\n",
    "        self.blocks = nn.Sequential(*[Block(dropout, embedding_dim, head_size, num_heads) for _ in range(num_layers)])\n",
    "        self.ln_f = nn.LayerNorm(embedding_dim)\n",
    "        self.lm_head = nn.Linear(embedding_dim, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #B, T = x.shape\n",
    "\n",
    "        data_embeddings = self.data_embedding(x)\n",
    "        positional_embeddings = self.position_embedding(torch.arange(time_period, device=device))\n",
    "        \n",
    "        x = data_embeddings + positional_embeddings\n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(dropout=0.2, embedding_dim=32, num_heads=4, head_size=8, num_layers=8).to(device)\n",
    "loss_function = nn.CrossEntropyLoss(reduction='mean')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), 1e-4)\n",
    "\n",
    "num_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.0005\n",
    "def get_targets(chunk):\n",
    "    # returns 1 hot encoding of whether the stock goes up or down\n",
    "    target = chunk[:, time_period, :]\n",
    "    chunk_real = chunk[:, :time_period, :]\n",
    "    \n",
    "    real_targets = []\n",
    "    for i in range(len(chunk_real)):\n",
    "        real_price = chunk_real[i, -1, 0]\n",
    "        target_price = target[i, 0]\n",
    "        if target_price > real_price*(1 + threshold):\n",
    "            # move up\n",
    "            real_targets.append([0, 0, 1])\n",
    "        elif target_price < real_price*(1 - threshold):\n",
    "            # move down\n",
    "            real_targets.append([1, 0, 0])\n",
    "        else:\n",
    "            # no change\n",
    "            real_targets.append([0, 1, 0])\n",
    "\n",
    "    return torch.tensor(real_targets, device=device, dtype=torch.float32)\n",
    "\n",
    "def normalize_features(real_chunk):\n",
    "    B, T, C = real_chunk.shape\n",
    "    #for j in range(time_period):\n",
    "    for j in range(B):\n",
    "    #    for i in range(feature_space):\n",
    "        for i in range(C):\n",
    "            # this current normalizes across the entire batch\n",
    "            # i think we want to normalize each feature across the entire time period, per batch\n",
    "            #feature_mean = sum(real_chunk[:, j, i]) / batch_size\n",
    "            #feature_stdev = torch.std(real_chunk[:, j, i])\n",
    "            #real_chunk[:, j, i] -= feature_mean\n",
    "            #real_chunk[:, j, i] /= feature_stdev\n",
    "\n",
    "            feature_mean = sum(real_chunk[j, :, i]) / T\n",
    "            feature_stdev = torch.std(real_chunk[j, :, i])\n",
    "            real_chunk[j, :, i] -= feature_mean\n",
    "            real_chunk[j, :, i] /= feature_stdev\n",
    "\n",
    "    return real_chunk\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103203\n",
      "0 4.294643878936768\n",
      "250 1.0138615369796753\n",
      "500 0.8266699910163879\n",
      "750 0.7146088480949402\n",
      "1000 0.6973654627799988\n",
      "1250 0.6649748682975769\n",
      "1500 0.6670117974281311\n",
      "1750 0.6492646932601929\n",
      "2000 0.6375779509544373\n",
      "2250 0.643650472164154\n",
      "2500 0.6505127549171448\n",
      "2750 0.6311330199241638\n",
      "3000 0.6178467273712158\n",
      "3250 0.6544930338859558\n",
      "3500 0.6178522706031799\n",
      "3750 0.6462894082069397\n",
      "4000 0.6284743547439575\n",
      "4250 0.6285868287086487\n",
      "4500 0.6165463328361511\n",
      "4750 0.670328676700592\n",
      "5000 0.6564711928367615\n",
      "5250 0.6337822079658508\n",
      "5500 0.6623955368995667\n",
      "5750 0.6356555819511414\n",
      "6000 0.5670194625854492\n",
      "6250 0.40460148453712463\n",
      "6500 0.3315158486366272\n",
      "6585\n"
     ]
    }
   ],
   "source": [
    "print(sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "losses = []\n",
    "iteration = 0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for chunk in dataloader:        \n",
    "        targets = get_targets(chunk)\n",
    "        chunk_real = chunk[:, :time_period, :].to(device)\n",
    "        normalized_chunk = normalize_features(chunk_real)\n",
    "        #print(normalized_chunk[:, 0, 0])\n",
    "        logits = model(normalized_chunk)\n",
    "        \n",
    "        #logit_probs = F.softmax(logits[:, -1, :], dim=-1)\n",
    "        #logits = F.softmax(logits[:, -1, :], dim=-1)\n",
    "       # loss = loss_function(logit_probs, targets)\n",
    "        loss = loss_function(logits, targets)\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        if iteration % 250 == 0:\n",
    "            print(iteration, loss.item())\n",
    "        \n",
    "        iteration += 1\n",
    "\n",
    "torch.save(model, 'model/btc15train')\n",
    "\n",
    "\n",
    "print(iteration)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses[:len(losses)-1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model/btc15')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (data_embedding): Linear(in_features=7, out_features=32, bias=True)\n",
       "  (position_embedding): Embedding(60, 32)\n",
       "  (blocks): Sequential(\n",
       "    (0): Block(\n",
       "      (self_att): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Block(\n",
       "      (self_att): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): Block(\n",
       "      (self_att): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Block(\n",
       "      (self_att): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (4): Block(\n",
       "      (self_att): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Block(\n",
       "      (self_att): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (6): Block(\n",
       "      (self_att): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): Block(\n",
       "      (self_att): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-3): 4 x Head(\n",
       "            (key): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (query): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (value): Linear(in_features=32, out_features=8, bias=False)\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (dropout): Dropout(p=0.2, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=32, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "          (3): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (ln_f): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=32, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('model/btc15'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get previous data, run a 60 second thing through it, buy at the close, sell at the next close, evaluate\n",
    "# how much money was made\n",
    "\n",
    "request_params = CryptoBarsRequest(\n",
    "    symbol_or_symbols=[\"BTC/USD\"],\n",
    "    timeframe=TimeFrame(amount=15, unit=TimeFrameUnit('Min')),\n",
    "    #timeframe=TimeFrame.Minute,\n",
    "    start=\"2024-05-18\",\n",
    "    end=\"2024-05-22\"\n",
    ")\n",
    "\n",
    "btc_bars = client.get_crypto_bars(request_params=request_params)\n",
    "\n",
    "dates = []\n",
    "stats = []\n",
    "for item in btc_bars[\"BTC/USD\"]:\n",
    "    dates.append(dict(item)['timestamp'])\n",
    "    \n",
    "    temp_stats = []\n",
    "    for key, value in dict(item).items():\n",
    "        if key not in ['timestamp', 'symbol']:\n",
    "            temp_stats.append(value) \n",
    "    stats.append(temp_stats)\n",
    "    \n",
    "testing_data = torch.tensor(stats, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([67118.1094, 67118.1094, 66935.9922, 67000.4297,     0.0000,     0.0000,\n",
      "            0.0000], device='mps:0')\n",
      "tensor([66988.4375, 66989.7031, 66827.0547, 66827.0547,     0.0000,     0.0000,\n",
      "            0.0000], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "print(testing_data[0]) #[open, high, low, close]\n",
    "print(testing_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2071, 0.4781, 0.3148], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2124, 0.5148, 0.2727], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2610, 0.4642, 0.2749], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2592, 0.4655, 0.2753], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2161, 0.4879, 0.2960], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1977, 0.5036, 0.2987], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1928, 0.5036, 0.3036], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2528, 0.4821, 0.2652], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2243, 0.4955, 0.2802], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2028, 0.5008, 0.2964], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2601, 0.4844, 0.2556], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2231, 0.4913, 0.2856], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2148, 0.4936, 0.2916], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2253, 0.4850, 0.2897], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2278, 0.4860, 0.2862], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2623, 0.4606, 0.2771], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2443, 0.4706, 0.2851], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2069, 0.4941, 0.2991], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2278, 0.4968, 0.2755], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2159, 0.4913, 0.2928], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2019, 0.5022, 0.2959], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2007, 0.5039, 0.2953], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1918, 0.5092, 0.2990], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2693, 0.4763, 0.2544], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2164, 0.5047, 0.2789], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2060, 0.5019, 0.2921], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2220, 0.5016, 0.2764], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2398, 0.4700, 0.2902], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1957, 0.5047, 0.2996], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2267, 0.5006, 0.2727], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2002, 0.5062, 0.2935], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2402, 0.4742, 0.2856], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1903, 0.4998, 0.3099], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2127, 0.4980, 0.2893], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2058, 0.5020, 0.2922], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2161, 0.5142, 0.2698], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2408, 0.4749, 0.2842], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2209, 0.5050, 0.2742], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2238, 0.5073, 0.2689], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1995, 0.5002, 0.3003], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2217, 0.4953, 0.2830], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2313, 0.5060, 0.2628], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2146, 0.5018, 0.2836], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1986, 0.5005, 0.3009], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1930, 0.5082, 0.2988], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2192, 0.5044, 0.2764], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2571, 0.4643, 0.2786], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2238, 0.4982, 0.2779], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2317, 0.4995, 0.2688], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2047, 0.5248, 0.2705], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2341, 0.5009, 0.2650], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2160, 0.5318, 0.2522], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2532, 0.4773, 0.2695], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2279, 0.4979, 0.2742], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2595, 0.4740, 0.2664], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2529, 0.4768, 0.2703], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2216, 0.5053, 0.2731], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2247, 0.4975, 0.2778], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2193, 0.5029, 0.2778], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2553, 0.4814, 0.2633], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2224, 0.5105, 0.2671], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2241, 0.5048, 0.2711], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2537, 0.4639, 0.2823], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2613, 0.4763, 0.2624], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2026, 0.5100, 0.2874], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2189, 0.4966, 0.2846], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2210, 0.5011, 0.2778], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2211, 0.5097, 0.2692], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2244, 0.4963, 0.2793], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2089, 0.5140, 0.2771], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2198, 0.4976, 0.2826], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2441, 0.4887, 0.2672], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2257, 0.5072, 0.2671], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2292, 0.5024, 0.2684], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2182, 0.5031, 0.2786], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2184, 0.5121, 0.2695], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2169, 0.4984, 0.2847], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1931, 0.4667, 0.3402], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1977, 0.5639, 0.2384], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2186, 0.5139, 0.2676], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2196, 0.5219, 0.2585], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1979, 0.5047, 0.2974], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2268, 0.5001, 0.2731], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2319, 0.4924, 0.2757], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2136, 0.5483, 0.2381], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1939, 0.5121, 0.2939], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2216, 0.5064, 0.2720], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2288, 0.4662, 0.3050], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2292, 0.4826, 0.2882], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2135, 0.4783, 0.3082], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1897, 0.4948, 0.3155], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2279, 0.4909, 0.2811], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2251, 0.5062, 0.2687], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2290, 0.4980, 0.2730], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2376, 0.4930, 0.2693], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2320, 0.4818, 0.2862], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2023, 0.4850, 0.3127], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2342, 0.4970, 0.2688], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2223, 0.4609, 0.3168], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2311, 0.4911, 0.2778], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2305, 0.4826, 0.2870], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2350, 0.4638, 0.3012], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2268, 0.4909, 0.2823], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2396, 0.4835, 0.2770], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2209, 0.4736, 0.3055], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2327, 0.4875, 0.2797], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2452, 0.4765, 0.2783], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2183, 0.4698, 0.3120], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2344, 0.4763, 0.2892], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2246, 0.4711, 0.3043], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2405, 0.4675, 0.2919], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2113, 0.4872, 0.3015], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2333, 0.4681, 0.2986], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2366, 0.4741, 0.2894], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2290, 0.4739, 0.2972], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2317, 0.4701, 0.2982], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2223, 0.4696, 0.3081], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2338, 0.4637, 0.3025], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2306, 0.4697, 0.2997], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2281, 0.4706, 0.3013], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2284, 0.4707, 0.3008], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2279, 0.4604, 0.3117], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2151, 0.4721, 0.3128], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2229, 0.4615, 0.3156], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2206, 0.4838, 0.2956], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2378, 0.4747, 0.2875], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2149, 0.4783, 0.3068], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2304, 0.4779, 0.2916], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2284, 0.4777, 0.2940], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2220, 0.4804, 0.2976], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2165, 0.4809, 0.3026], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2359, 0.4730, 0.2912], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2218, 0.4800, 0.2982], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2046, 0.4872, 0.3082], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1987, 0.4906, 0.3107], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2328, 0.4773, 0.2899], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2161, 0.4853, 0.2986], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2049, 0.4855, 0.3096], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2288, 0.4790, 0.2922], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1980, 0.4940, 0.3080], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1978, 0.4979, 0.3043], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2111, 0.5015, 0.2874], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2170, 0.4961, 0.2869], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2316, 0.4846, 0.2838], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2235, 0.4989, 0.2776], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1954, 0.5095, 0.2951], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2164, 0.4991, 0.2845], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2071, 0.4968, 0.2961], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2130, 0.5015, 0.2854], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2171, 0.4801, 0.3028], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2525, 0.4810, 0.2666], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2142, 0.4976, 0.2882], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2434, 0.4926, 0.2640], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2416, 0.4907, 0.2678], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2437, 0.4897, 0.2666], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2132, 0.5048, 0.2819], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2218, 0.4984, 0.2798], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2150, 0.4977, 0.2873], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1955, 0.5482, 0.2563], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1863, 0.5105, 0.3032], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2067, 0.5039, 0.2894], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2451, 0.4787, 0.2762], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2125, 0.5029, 0.2846], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2194, 0.5020, 0.2786], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2136, 0.4972, 0.2892], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2097, 0.5068, 0.2835], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2181, 0.5002, 0.2817], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2054, 0.5065, 0.2881], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2164, 0.4992, 0.2845], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2261, 0.4993, 0.2746], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2123, 0.4980, 0.2896], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2688, 0.4665, 0.2647], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2080, 0.4954, 0.2966], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2175, 0.5011, 0.2813], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2214, 0.4924, 0.2862], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2553, 0.4746, 0.2702], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2530, 0.4794, 0.2676], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2156, 0.5050, 0.2794], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2104, 0.5060, 0.2836], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2628, 0.4672, 0.2700], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2145, 0.5026, 0.2828], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2153, 0.5186, 0.2661], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2041, 0.5108, 0.2851], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2187, 0.4908, 0.2905], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2511, 0.4775, 0.2714], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2307, 0.4978, 0.2715], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2572, 0.4621, 0.2807], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2231, 0.5080, 0.2688], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2679, 0.4717, 0.2604], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2392, 0.4842, 0.2766], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2147, 0.4791, 0.3062], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2463, 0.4598, 0.2938], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2423, 0.4632, 0.2945], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2477, 0.4796, 0.2727], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2467, 0.4915, 0.2618], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2418, 0.4790, 0.2792], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2383, 0.4962, 0.2655], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2332, 0.4825, 0.2843], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2197, 0.4944, 0.2859], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2286, 0.5042, 0.2672], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2270, 0.5085, 0.2645], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2277, 0.5056, 0.2667], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2435, 0.4871, 0.2694], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2435, 0.4874, 0.2691], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2444, 0.4812, 0.2744], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2545, 0.4650, 0.2805], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2184, 0.5011, 0.2805], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2331, 0.4995, 0.2673], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2497, 0.4757, 0.2746], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2410, 0.4719, 0.2871], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1952, 0.4762, 0.3287], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2166, 0.5170, 0.2664], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2306, 0.5029, 0.2665], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2278, 0.4798, 0.2924], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2366, 0.4913, 0.2720], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2277, 0.5028, 0.2695], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2482, 0.4808, 0.2711], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2306, 0.4976, 0.2718], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2388, 0.4939, 0.2673], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2159, 0.4975, 0.2867], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2296, 0.4976, 0.2728], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2193, 0.4977, 0.2830], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2173, 0.4994, 0.2833], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2464, 0.4864, 0.2672], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1833, 0.4555, 0.3612], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2293, 0.4982, 0.2726], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2320, 0.5001, 0.2679], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2266, 0.5016, 0.2718], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2508, 0.4750, 0.2742], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2264, 0.4970, 0.2766], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2269, 0.5006, 0.2725], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2262, 0.4982, 0.2756], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2140, 0.4958, 0.2902], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2338, 0.4916, 0.2747], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2205, 0.4935, 0.2860], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2172, 0.4956, 0.2871], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2351, 0.4929, 0.2720], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2332, 0.4927, 0.2741], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2155, 0.4939, 0.2906], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2305, 0.4946, 0.2750], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2166, 0.4933, 0.2902], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2353, 0.4929, 0.2718], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2301, 0.4919, 0.2780], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2320, 0.4916, 0.2765], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2320, 0.4898, 0.2782], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2289, 0.4926, 0.2784], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2248, 0.4906, 0.2846], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2192, 0.4937, 0.2871], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2229, 0.4913, 0.2858], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2286, 0.4906, 0.2808], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2298, 0.4869, 0.2834], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2293, 0.4925, 0.2781], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2284, 0.4903, 0.2813], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2305, 0.4895, 0.2801], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2180, 0.4964, 0.2856], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2255, 0.4939, 0.2807], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2327, 0.4911, 0.2761], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2293, 0.4948, 0.2759], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2172, 0.4954, 0.2874], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2318, 0.4818, 0.2864], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2457, 0.4808, 0.2736], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2279, 0.4940, 0.2781], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2341, 0.4872, 0.2787], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2251, 0.4893, 0.2856], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2270, 0.4931, 0.2799], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2177, 0.4997, 0.2825], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2266, 0.4930, 0.2804], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2318, 0.4821, 0.2861], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2196, 0.4954, 0.2850], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2265, 0.4928, 0.2807], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2283, 0.4970, 0.2747], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2328, 0.4896, 0.2777], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2361, 0.4844, 0.2795], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2163, 0.4963, 0.2874], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2238, 0.4985, 0.2777], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2173, 0.4946, 0.2881], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2327, 0.4904, 0.2768], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2288, 0.4952, 0.2760], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2332, 0.4879, 0.2789], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2268, 0.5060, 0.2673], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2346, 0.5108, 0.2546], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2416, 0.4932, 0.2653], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2260, 0.5449, 0.2291], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2194, 0.4847, 0.2959], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2059, 0.5091, 0.2850], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2278, 0.4646, 0.3076], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2478, 0.4923, 0.2598], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2250, 0.4685, 0.3065], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2448, 0.4664, 0.2888], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2356, 0.4762, 0.2882], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2393, 0.4874, 0.2733], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2482, 0.4732, 0.2786], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2449, 0.4706, 0.2844], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2317, 0.4827, 0.2856], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2383, 0.4698, 0.2919], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2317, 0.4677, 0.3006], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2311, 0.4624, 0.3065], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2341, 0.4695, 0.2964], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2318, 0.4690, 0.2992], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2350, 0.4729, 0.2921], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2242, 0.4733, 0.3025], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2356, 0.4674, 0.2969], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2293, 0.4588, 0.3119], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2278, 0.4697, 0.3025], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2180, 0.4910, 0.2909], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2403, 0.4645, 0.2952], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2501, 0.4684, 0.2815], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2111, 0.4695, 0.3194], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2200, 0.4814, 0.2986], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2102, 0.4815, 0.3083], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2191, 0.4847, 0.2963], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2219, 0.4839, 0.2942], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2225, 0.4764, 0.3012], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2188, 0.4811, 0.3002], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2167, 0.4901, 0.2931], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2202, 0.4878, 0.2920], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2192, 0.4896, 0.2912], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2175, 0.4930, 0.2895], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.1999, 0.5015, 0.2986], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2064, 0.4961, 0.2975], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2005, 0.5043, 0.2952], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2032, 0.4996, 0.2972], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.2073, 0.5021, 0.2906], device='mps:0', grad_fn=<SoftmaxBackward0>)\n",
      "Iterations: 323, buys: 0, sells: 0\n"
     ]
    }
   ],
   "source": [
    "cash = 1000\n",
    "iterations = 0\n",
    "num_sells = 0\n",
    "num_buys = 0\n",
    "for bar in range(len(testing_data) - time_period):\n",
    "    test_context = testing_data[bar:bar+time_period].view(1, time_period, feature_space).detach().clone()\n",
    "    test_target = testing_data[bar+time_period].detach().clone()\n",
    "    \n",
    "    buying_price = test_context[0, -1, 3].detach().clone() # closing price\n",
    "    selling_price = test_target[0].detach().clone()\n",
    "\n",
    "    #print(buying_price, selling_price)\n",
    "\n",
    "    normalized_context = normalize_features(test_context)\n",
    "\n",
    "    logits = model(normalized_context)\n",
    "    \n",
    "    print(F.softmax(logits[0, -1], dim=-1))\n",
    "\n",
    "    decision = torch.argmax(logits[0, -1])\n",
    "    \n",
    "    \n",
    "    if decision == 2:\n",
    "        # buy signal\n",
    "        #print(selling_price-buying_price)\n",
    "        cash += (selling_price - buying_price)\n",
    "        num_buys += 1\n",
    "    elif decision == 1:\n",
    "        # do nothing\n",
    "        pass\n",
    "    elif decision == 0:\n",
    "        # sell signal\n",
    "        cash += (buying_price - selling_price)\n",
    "        num_sells += 1\n",
    "        pass\n",
    "    else:\n",
    "        # error\n",
    "        print(\"Bad\")\n",
    "    \n",
    "    #print(cash)\n",
    "    iterations += 1\n",
    "\n",
    "    \n",
    "\n",
    "print(f'Iterations: {iterations}, buys: {num_buys}, sells: {num_sells}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    }
   ],
   "source": [
    "# next steps: normalize/scale the features,,,,???? center around 0 and 1 STDEV, should be a cool way to do this in pytorch\n",
    "# rewrite the code to be more clean\n",
    "\n",
    "#back test this on some new data\n",
    "print(cash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
